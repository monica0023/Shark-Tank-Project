ğŸ§  MemoTag â€“ Speech Intelligence for Early Cognitive Risk Detection

This project analyzes anonymized voice clips from the Mozilla Common Voice dataset to detect potential early signs of cognitive impairment such as memory issues, slowed speech, or reduced fluency.

ğŸ“ Goal: Build a lightweight, explainable, and scalable pipeline to extract voice features and detect anomalies using unsupervised machine learning.

ğŸ“ Dataset

Source: Mozilla Common Voice (English)

Samples Used: 10 audio clips (e.g., common_voice_en_42693855.mp3)

Format: .mp3 files, ~5â€“10 sec each

ğŸ› ï¸ Features Extracted

Feature	Description

ğŸ—£ï¸ speech_rate	- Words per second (wpm estimate)

ğŸ˜¶ hesitation_count - 	Filler words like â€œuhâ€, â€œumâ€, â€œerâ€

ğŸµ pitch_mean	 - Average voice pitch (from librosa)

ğŸ¶ pitch_std - 	Pitch variation (standard deviation)

ğŸ§¾ word_count - Total words spoken

â¸ï¸ pauses - 	Silence duration between words

ğŸ“Š similarity_score	Optional: match spoken vs. expected sentence

ğŸ¤– ML Approach

âœ… Isolation Forest

Unsupervised anomaly detection

Flags â€œat-riskâ€ speech patterns without labeled data

Visualized using pitch vs speech rate

ğŸ“ˆ Sample Output

bash
Copy code
Filename: common_voice_en_42693856.mp3
Speech Rate: 1.2 wps
Hesitations: 4
Pitch Mean: 250 Hz
Pitch Std: 200
--> Risk Level: âš ï¸ At Risk

ğŸ“Œ Key Highlights

ğŸ“¦ Uses OpenAI Whisper for transcription

ğŸ“Š Feature Engineering with librosa, difflib, and basic NLP

ğŸ“‰ IsolationForest from scikit-learn for anomaly detection

ğŸ“ Interpretable results for future clinical applications

ğŸ’¡ Credits

Dataset by Mozilla Common Voice

Model: OpenAI Whisper, Librosa, Scikit-learn

Project by Monica for MemoTag's Speech Intelligence Module

ğŸ“¬ Contact

For collaboration, reach out via https://www.linkedin.com/in/monica-r-tech-innovator/ or monica.r.041002@gmail.com.
